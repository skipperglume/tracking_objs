{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import Video, display, Image\n",
    "import imageio\n",
    "\n",
    "from tracker_yolo.TrackObject import TrackedObject, Detection\n",
    "from tracker_yolo.utils import create_tracker, bbox_center\n",
    "from tracker_yolo.utils import iou, estimate_speed_mean, overlaps_existing_track\n",
    "from tracker_yolo.utils import associate_detections\n",
    "from tracker_yolo.plotting import draw_kalman_prediction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = YOLO(\"models/yolo26s.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb53cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.__version__)\n",
    "print(hasattr(cv2, \"TrackerCSRT_create\"))\n",
    "# Use CV2 to open images\n",
    "# im1 = cv2.imread(\"Inputs/bridge_cars.jpg\")\n",
    "# im1 = cv2.imread(\"Inputs/car_behind_rails.jpg\")\n",
    "im1 = cv2.imread(\"Inputs/car_stop.jpg\")\n",
    "results = model.predict(source=im1, save=True, show=False)  # save plotted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the im1 dimensions:\n",
    "print(f\"Image 1 dimensions: {im1.shape}\")\n",
    "\n",
    "\n",
    "print(type(results))\n",
    "print(len(results))\n",
    "print(dir(results[0]))\n",
    "# print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 38)\n",
    "print(\"boxes\")\n",
    "# print(results[0].boxes)\n",
    "print(results[0].boxes.cls)\n",
    "print(dir(results[0].boxes))\n",
    "print(results[0].boxes.xyxy) # Positions of the bounding boxes in xyxy format\n",
    "# print(results[0].boxes.xywh) # Positions of the bounding boxes in xywh format (center x, center y, width, height)\n",
    "# print(results[0].names)\n",
    "\n",
    "print([results[0].names[int(_)] for _ in results[0].boxes.cls])\n",
    "print(\"-\" * 38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(im1.size)\n",
    "# Plot only image and boxes using matplotlib\n",
    "plt.imshow(im1)\n",
    "for box in results[0].boxes:\n",
    "    x1, y1, x2, y2 = box.xyxy[0]\n",
    "    width, height = x2 - x1, y2 - y1\n",
    "    rect = plt.Rectangle((x1, y1), width, height, fill=False, color='red', linewidth=2)\n",
    "    plt.gca().add_patch(rect)\n",
    "    # Plot class label\n",
    "    cls = int(box.cls[0])\n",
    "    plt.text(x1, y1, results[0].names[cls], color='white', fontsize=12, backgroundcolor='red')\n",
    "plt.axis('off')  # Hide axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = \"Inputs/static_cam_cars.mp4\"\n",
    "if not os.path.exists(input_video_path):\n",
    "    raise(f\"Input video not found at path: {input_video_path}\")\n",
    "\n",
    "\n",
    "out_dir = os.path.basename(input_video_path).split('.')[0]\n",
    "out_dir = os.path.join(\"Outputs/\", out_dir)\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "# TODO: Finish the [out_dir] usage!\n",
    "print(f'Output dir: [{out_dir}]')\n",
    "\n",
    "frame_iter = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame_iter += 1\n",
    "    if frame_iter % 30 == 0:\n",
    "        print(f\"Frame {frame_iter}\")\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "\n",
    "# Print total number of frames\n",
    "print(f\"Total number of frames: {frame_iter}\")\n",
    "# Print the rate of frames per second\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"Frames per second: {fps}\")\n",
    "print(f\"Duration of the video: {frame_iter / fps:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6700b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Get length of the video\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Total number of frames: {length}. \")\n",
    "video_duration = length / fps\n",
    "print(f\"Video duration (s): {video_duration:.2f}. \")\n",
    "print(f'Video FPS: {fps:.2f}, Width: {width}, Height: {height}')\n",
    "\n",
    "# writer = cv2.VideoWriter(\n",
    "#     \"Outputs/tracked_output.mp4\",\n",
    "#     cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "#     fps,\n",
    "#     (width, height)\n",
    "# )\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "# fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"MP4V\")\n",
    "# fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "# 0x31637661  # 'avc1' in little endian\n",
    "# fourcc = 0x31637661  # 'avc1' in little endian\n",
    "writer = cv2.VideoWriter(\n",
    "    \"Outputs/tracked_output.mp4\",  # <-- .avi !\n",
    "    fourcc,\n",
    "    fps,\n",
    "    (width, height),\n",
    ")\n",
    "\n",
    "\n",
    "gif_writer = imageio.get_writer(\n",
    "    \"Outputs/tracked_output.gif\",\n",
    "    mode=\"I\",\n",
    "    fps=5,          # lower FPS - better visible what's going on\n",
    "    loop=0,   # 0 = infinite loop\n",
    ")\n",
    "\n",
    "tracked_objects = []\n",
    "# TrackedObject._next_id = 0\n",
    "TrackedObject.reset_ids()\n",
    "# For FPS=30\n",
    "MAX_MISSED = 30 # Max missed frames before deleting track\n",
    "YOLO_INTERVAL = 15 # Run YOLO every N frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af014a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    use_yolo = frame_idx % YOLO_INTERVAL == 0\n",
    "\n",
    "\n",
    "    for obj_id, obj in enumerate(tracked_objects):\n",
    "        obj.predict_kf()\n",
    "\n",
    "    if use_yolo:\n",
    "\n",
    "\n",
    "        results = model.predict(frame, conf=0.3, verbose=False)[0]\n",
    "\n",
    "        detections = []\n",
    "        if results.boxes is not None:\n",
    "            for box, cls, conf in zip(\n",
    "                results.boxes.xyxy.cpu().numpy(),\n",
    "                results.boxes.cls.cpu().numpy(),\n",
    "                results.boxes.conf.cpu().numpy(),\n",
    "            ):\n",
    "                found_object_class = results.names[int(cls)]\n",
    "                if found_object_class == \"car\":\n",
    "                    detections.append(\n",
    "                        Detection(bbox=box, conf=conf, cls=int(cls))\n",
    "                    )\n",
    "                # else: \n",
    "                    # print(f'Found object of class: [{found_object_class}]')\n",
    "\n",
    "\n",
    "            # --- association ---\n",
    "            matches, unmatched_tracks, unmatched_dets = associate_detections(\n",
    "                tracked_objects, detections\n",
    "            )\n",
    "\n",
    "            # update matched tracks\n",
    "            for t_idx, d_idx in matches:\n",
    "                tracked_objects[t_idx].update(detections[d_idx])\n",
    "\n",
    "            # mark missed tracks\n",
    "            for t_idx in unmatched_tracks:\n",
    "                tracked_objects[t_idx].mark_missed()\n",
    "\n",
    "            # create new tracks\n",
    "            for d_idx in unmatched_dets:\n",
    "                det = detections[d_idx]\n",
    "                # With condition to avoid duplicates\n",
    "                if not overlaps_existing_track(det, tracked_objects):\n",
    "                    tracked_objects.append(TrackedObject(det, fps, frame))\n",
    "\n",
    "            # remove dead tracks\n",
    "            tracked_objects = [\n",
    "                t for t in tracked_objects if t.missed <= MAX_MISSED\n",
    "            ]\n",
    "\n",
    "\n",
    "        # --- draw all detections ---\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = map(int, det.bbox)\n",
    "            # BRG\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # --- draw unmatched detections (orange) ---\n",
    "        for d_idx in unmatched_dets:\n",
    "            det = detections[d_idx]\n",
    "            x1, y1, x2, y2 = map(int, det.bbox)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Tracker-only update\n",
    "        for track in tracked_objects:\n",
    "            track.update_from_tracker(frame)\n",
    "\n",
    "        # No detections: mark all as missed\n",
    "        for track in tracked_objects:\n",
    "            track.mark_missed()\n",
    "\n",
    "        # remove dead tracks\n",
    "        tracked_objects = [\n",
    "            t for t in tracked_objects if t.missed <= MAX_MISSED\n",
    "        ]\n",
    "\n",
    "\n",
    "    if frame_idx%30 == 0:\n",
    "        # Create a sorted list of IOU values between all tracked objects\n",
    "        iou_values = []\n",
    "        for i in range(len(tracked_objects)):\n",
    "            for j in range(i + 1, len(tracked_objects)):\n",
    "                iou_score = iou(tracked_objects[i].bbox, tracked_objects[j].bbox)\n",
    "                iou_values.append((tracked_objects[i].id, tracked_objects[j].id, iou_score))\n",
    "        iou_values.sort(key=lambda x: x[2], reverse=True)\n",
    "        # print(f'Frame {frame_idx}: Top IOU values between tracked objects:')\n",
    "        # for id1, id2, score in iou_values[:5]:  # Print top 5 IOU values\n",
    "        #     print(f'  IDs {id1} & {id2}: IOU = {score:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "    # On top right corner, print frame idx, number of active tracks and info if it's yolo frame or not:\n",
    "    info_text = f'Frame {frame_idx}; Duration {frame_idx/fps:.2f}s; Active Tracks: {len(tracked_objects)}; ' + \\\n",
    "                ('[YOLO]' if use_yolo else '[Trac]')\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        info_text,\n",
    "        (10, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (0, 255, 255),\n",
    "        2,\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    # if frame_idx % 10 == 0:\n",
    "    #     print(f'Frame {frame_idx}; Duration {frame_idx/fps:.2f}: {len(tracked_objects)} active tracks')\n",
    "    #     # Print number of matches, unmatched tracks, unmatched detections\n",
    "    #     print(f'  Matches: {len(matches)}, Unmatched Tracks: {len(unmatched_tracks)}, Unmatched Detections: {len(unmatched_dets)}')\n",
    "\n",
    "\n",
    "    # --- draw ---\n",
    "    for obj in tracked_objects:\n",
    "        x1, y1, x2, y2 = map(int, obj.bbox)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"ID {obj.id}\",\n",
    "            (x1, y1 - 5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "    \n",
    "    speed_list = []\n",
    "    # Update timeticks for all tracked objects\n",
    "    for obj_id, obj in enumerate(tracked_objects):\n",
    "        # List to store speed estimates per track object:\n",
    "\n",
    "        obj.update_timeticks(frame_idx, fps)\n",
    "\n",
    "        # obj_speed = estimate_speed(obj)\n",
    "        obj_speed = estimate_speed_mean(obj)\n",
    "\n",
    "        speed_list.append((obj.id, obj_speed))\n",
    "\n",
    "        # if frame_idx % 10 == 0:\n",
    "        #     if obj_speed is not None:\n",
    "        #         print(f'{obj.id} : {obj_speed:.2f} [m/s] : {(obj_speed*3.6):.2f} [km/h]')\n",
    "\n",
    "    speed_n_entries = 7\n",
    "\n",
    "    # Put text of highest `speed_n_entries` tracks on the frame\n",
    "    # Skip if speed is None\n",
    "    for track_id, track_speed in sorted(speed_list, key=lambda x: x[1] if x[1] is not None else -1, reverse=True)[:speed_n_entries]:\n",
    "        if track_speed is not None:\n",
    "            # Find the corresponding tracked object to get its bbox\n",
    "            for obj in tracked_objects:\n",
    "                if obj.id == track_id:\n",
    "                    x1, y1, x2, y2 = map(int, obj.bbox)\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        f\"{track_speed*3.6:.1f} km/h\",\n",
    "                        (x1, y2 + 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.6,\n",
    "                        (255, 255, 0),\n",
    "                        2,\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "    for obj_id, obj in enumerate(tracked_objects):\n",
    "        draw_kalman_prediction(frame, obj, steps=30, color=(255, 0, 255))\n",
    "        # if obj.id in [9]:\n",
    "        #     print(f'KF info on obj [{obj.id}] at frame [{frame_idx}]')\n",
    "        #     print(f'position: {float(obj.kf.position[0]):.1f}, {float(obj.kf.position[1]):.1f}')\n",
    "        #     print(f'velocity: {float(obj.kf.velocity[0]):.1f}, {float(obj.kf.velocity[1]):.1f}')\n",
    "\n",
    "    \n",
    "\n",
    "    if frame_idx % 4 == 0:\n",
    "        gif_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        gif_writer.append_data(gif_frame)\n",
    "\n",
    "    # Add early stop for testing\n",
    "    # if frame_idx >= 180:\n",
    "    if frame_idx >= 120:\n",
    "    # if frame_idx >= 60:\n",
    "        break\n",
    "\n",
    "    writer.write(frame)\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "gif_writer.close()\n",
    "\n",
    "print(f\"Writer opened: {writer.isOpened()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86450903",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(\"Outputs/tracked_output.gif\", embed=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Video(\"Inputs/video.mp4\", embed=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f27df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
