{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from IPython.display import Video, display, Image\n",
    "import imageio\n",
    "\n",
    "model = YOLO(\"models/yolo26s.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb53cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv2.__version__)\n",
    "print(hasattr(cv2, \"TrackerCSRT_create\"))\n",
    "# Use CV2 to open images\n",
    "# im1 = cv2.imread(\"Inputs/bridge_cars.jpg\")\n",
    "# im1 = cv2.imread(\"Inputs/car_behind_rails.jpg\")\n",
    "im1 = cv2.imread(\"Inputs/car_stop.jpg\")\n",
    "results = model.predict(source=im1, save=True, show=False)  # save plotted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the im1 dimensions:\n",
    "print(f\"Image 1 dimensions: {im1.shape}\")\n",
    "\n",
    "\n",
    "print(type(results))\n",
    "print(len(results))\n",
    "print(dir(results[0]))\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 38)\n",
    "print(\"boxes\")\n",
    "print(results[0].boxes)\n",
    "print(results[0].boxes.cls)\n",
    "print(results[0].names)\n",
    "\n",
    "print([results[0].names[int(_)] for _ in results[0].boxes.cls])\n",
    "print(\"-\" * 38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(im1.size)\n",
    "# Plot only image and boxes using matplotlib\n",
    "plt.imshow(im1)\n",
    "for box in results[0].boxes:\n",
    "    x1, y1, x2, y2 = box.xyxy[0]\n",
    "    width, height = x2 - x1, y2 - y1\n",
    "    rect = plt.Rectangle((x1, y1), width, height, fill=False, color='red', linewidth=2)\n",
    "    plt.gca().add_patch(rect)\n",
    "    # Plot class label\n",
    "    cls = int(box.cls[0])\n",
    "    plt.text(x1, y1, results[0].names[cls], color='white', fontsize=12, backgroundcolor='red')\n",
    "plt.axis('off')  # Hide axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff12b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"Inputs/video.mp4\")\n",
    "\n",
    "frame_iter = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame_iter += 1\n",
    "    if frame_iter % 30 == 0:\n",
    "        print(f\"Frame {frame_iter}\")\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "# Print total number of frames\n",
    "print(f\"Total number of frames: {frame_iter}\")\n",
    "# Print the rate of frames per second\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"Frames per second: {fps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9539e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tracker():\n",
    "    return cv2.legacy.TrackerCSRT_create()\n",
    "\n",
    "def create_tracker_specified(tracker_type: str):\n",
    "    tracker_types = {\n",
    "        \"BOOSTING\": cv2.TrackerBoosting_create,\n",
    "        \"MIL\": cv2.TrackerMIL_create,\n",
    "        \"KCF\": cv2.TrackerKCF_create,\n",
    "        \"TLD\": cv2.TrackerTLD_create,\n",
    "        \"MEDIANFLOW\": cv2.TrackerMedianFlow_create,\n",
    "        \"GOTURN\": cv2.TrackerGOTURN_create,\n",
    "        \"MOSSE\": cv2.TrackerMOSSE_create,\n",
    "        \"CSRT\": cv2.TrackerCSRT_create,\n",
    "    }\n",
    "    if tracker_type in tracker_types:\n",
    "        return tracker_types[tracker_type]()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tracker type: {tracker_type}\")\n",
    "\n",
    "@dataclass\n",
    "class Detection:\n",
    "    '''\n",
    "    Class for objects to hold detection results. \n",
    "    '''\n",
    "\n",
    "    bbox: np.ndarray  # [x1, y1, x2, y2] - Bounding box on a frame\n",
    "    conf: float # Confidence score\n",
    "    cls: int # Class \n",
    "\n",
    "class TrackedObject:\n",
    "    _next_id = 0\n",
    "\n",
    "    def __init__(self, detection: Detection):\n",
    "        self.id = TrackedObject._next_id\n",
    "        TrackedObject._next_id += 1\n",
    "\n",
    "        x1, y1, x2, y2 = detection.bbox\n",
    "        self.tracker = create_tracker()\n",
    "        self.tracker.init(frame, (x1, y1, x2 - x1, y2 - y1))\n",
    "\n",
    "        self.bbox = detection.bbox\n",
    "        self.cls = detection.cls\n",
    "        self.conf = detection.conf\n",
    "\n",
    "        # Variables to store history (For velocity estimation, etc.)\n",
    "        self.fame_ids = [] # List of indices of frames where this object was detected\n",
    "        self.timestamps = [] # List of timestamps corresponding to the frames\n",
    "        self.centers = [] # List of center points of the bounding boxes\n",
    "\n",
    "        self.hits = 1          # number of successful matches when associating new detections to existing tracks\n",
    "        self.age = 0              # total frames alive\n",
    "        self.missed = 0           # frames since last match\n",
    "\n",
    "    @classmethod\n",
    "    def reset_ids(cls):\n",
    "        cls._next_id = 0\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        For now: no motion model.\n",
    "        Later: Kalman filter lives here.\n",
    "        \"\"\"\n",
    "        return self.bbox\n",
    "\n",
    "    def update_timeticks(self, frame_id:int, fps:float):\n",
    "        timestamp = frame_id / fps\n",
    "        self.fame_ids.append(frame_id)\n",
    "        self.centers.append(bbox_center(self.bbox))\n",
    "        self.timestamps.append(timestamp)\n",
    "\n",
    "    def update(self, detection: Detection):\n",
    "        self.bbox = detection.bbox\n",
    "        self.conf = detection.conf\n",
    "        self.missed = 0\n",
    "        self.age += 1\n",
    "        self.hits += 1\n",
    "\n",
    "    def update_from_tracker(self, frame):\n",
    "        ok, box = self.tracker.update(frame)\n",
    "        if not ok:\n",
    "            self.missed += 1\n",
    "            return False\n",
    "\n",
    "        x, y, w, h = box\n",
    "        self.bbox = np.array([x, y, x + w, y + h])\n",
    "        self.missed = 0\n",
    "        self.age += 1\n",
    "        return True\n",
    "\n",
    "    def mark_missed(self):\n",
    "        '''\n",
    "        Mark this object as missed in the current frame.\n",
    "        '''\n",
    "        self.missed += 1\n",
    "        self.age += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdebfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(boxA, boxB):\n",
    "    '''\n",
    "    Method to compute Intersection over Union (IoU) between two bounding boxes.\n",
    "    Compute area of overlap / area of union\n",
    "    If intersection is zero, returns 0\n",
    "    '''\n",
    "    \n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    inter = max(0, xB - xA) * max(0, yB - yA) # area of intersection\n",
    "    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]) # area of boxA\n",
    "    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]) # area of boxB\n",
    "\n",
    "    union = areaA + areaB - inter # area of union\n",
    "    return inter / union if union > 0 else 0 # Return IoU value\n",
    "\n",
    "\n",
    "def bbox_center(box):\n",
    "    '''\n",
    "    Take a plain average to get the center of a bounding box.\n",
    "    '''\n",
    "\n",
    "    x1, y1, x2, y2 = box\n",
    "    return np.array([(x1 + x2) / 2, (y1 + y2) / 2])\n",
    "\n",
    "\n",
    "def center_distance(boxA, boxB):\n",
    "    '''\n",
    "    Evaluate the Euclidean distance between the centers of two bounding boxes.\n",
    "    '''\n",
    "    return np.linalg.norm(bbox_center(boxA) - bbox_center(boxB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e764bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_detections(tracked_objects, detections, iou_threshold=0.3):\n",
    "    '''\n",
    "    Method that \n",
    "    '''\n",
    "\n",
    "    matches = [] # list of (track_idx, detection_idx) tuples\n",
    "    unmatched_tracks = set(range(len(tracked_objects))) # set of unmatched track indices\n",
    "    unmatched_dets = set(range(len(detections))) # set of unmatched detection indices\n",
    "\n",
    "    for t_idx, track in enumerate(tracked_objects):\n",
    "        best_iou = 0\n",
    "        best_d_idx = None # Best detection index\n",
    "\n",
    "        for d_idx in unmatched_dets:\n",
    "            score = iou(track.predict(), detections[d_idx].bbox)\n",
    "            if score > best_iou:\n",
    "                best_iou = score\n",
    "                best_d_idx = d_idx\n",
    "\n",
    "        if best_iou > iou_threshold:\n",
    "            matches.append((t_idx, best_d_idx))\n",
    "            unmatched_tracks.remove(t_idx)\n",
    "            unmatched_dets.remove(best_d_idx)\n",
    "\n",
    "    return matches, unmatched_tracks, unmatched_dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149316e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps_existing_track(detection, tracked_objects, iou_threshold=0.75):\n",
    "    for track in tracked_objects:\n",
    "        if iou(track.bbox, detection.bbox) > iou_threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def bbox_length_px(bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    return max(w, h)\n",
    "\n",
    "def estimate_speed(track, car_length_m=4.3):\n",
    "    if len(track.centers) < 2:\n",
    "        return None\n",
    "\n",
    "    position_1 = track.centers[-2]\n",
    "    position_2 = track.centers[-1]\n",
    "    dt = track.timestamps[-1] - track.timestamps[-2]\n",
    "\n",
    "    dposition_px = np.linalg.norm(position_2 - position_1)\n",
    "\n",
    "    L_px = bbox_length_px(track.bbox)\n",
    "    meters_per_pixel = car_length_m / L_px\n",
    "\n",
    "    speed_mps = dposition_px * meters_per_pixel / dt\n",
    "    return speed_mps\n",
    "\n",
    "def smooth_speed(prev, new, alpha=0.3):\n",
    "    if prev is None:\n",
    "        return new\n",
    "    return alpha * new + (1 - alpha) * prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6700b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"Inputs/video.mp4\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Get length of the video\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"Total number of frames: {length}. \")\n",
    "video_duration = length / fps\n",
    "print(f\"Video duration (s): {video_duration:.2f}. \")\n",
    "print(f'Video FPS: {fps:.2f}, Width: {width}, Height: {height}')\n",
    "\n",
    "# writer = cv2.VideoWriter(\n",
    "#     \"Outputs/tracked_output.mp4\",\n",
    "#     cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "#     fps,\n",
    "#     (width, height)\n",
    "# )\n",
    "\n",
    "# fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "# fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"MP4V\")\n",
    "# fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "# 0x31637661  # 'avc1' in little endian\n",
    "# fourcc = 0x31637661  # 'avc1' in little endian\n",
    "writer = cv2.VideoWriter(\n",
    "    \"Outputs/tracked_output.mp4\",  # <-- .avi !\n",
    "    fourcc,\n",
    "    fps,\n",
    "    (width, height),\n",
    ")\n",
    "\n",
    "\n",
    "gif_writer = imageio.get_writer(\n",
    "    \"Outputs/tracked_output.gif\",\n",
    "    mode=\"I\",\n",
    "    fps=10,          # lower FPS - better visible what's going on\n",
    "    loop=0,   # 0 = infinite loop\n",
    ")\n",
    "\n",
    "tracked_objects = []\n",
    "# TrackedObject._next_id = 0\n",
    "TrackedObject.reset_ids()\n",
    "# For FPS=30\n",
    "MAX_MISSED = 30 # Max missed frames before deleting track\n",
    "YOLO_INTERVAL = 15 # Run YOLO every N frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af014a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    use_yolo = frame_idx % YOLO_INTERVAL == 0\n",
    "\n",
    "    if use_yolo:\n",
    "\n",
    "\n",
    "        results = model.predict(frame, conf=0.3, verbose=False)[0]\n",
    "\n",
    "        detections = []\n",
    "        if results.boxes is not None:\n",
    "            for box, cls, conf in zip(\n",
    "                results.boxes.xyxy.cpu().numpy(),\n",
    "                results.boxes.cls.cpu().numpy(),\n",
    "                results.boxes.conf.cpu().numpy(),\n",
    "            ):\n",
    "                found_object_class = results.names[int(cls)]\n",
    "                if found_object_class == \"car\":\n",
    "                    detections.append(\n",
    "                        Detection(bbox=box, conf=conf, cls=int(cls))\n",
    "                    )\n",
    "                # else: \n",
    "                    # print(f'Found object of class: [{found_object_class}]')\n",
    "\n",
    "\n",
    "            # --- association ---\n",
    "            matches, unmatched_tracks, unmatched_dets = associate_detections(\n",
    "                tracked_objects, detections\n",
    "            )\n",
    "\n",
    "            # update matched tracks\n",
    "            for t_idx, d_idx in matches:\n",
    "                tracked_objects[t_idx].update(detections[d_idx])\n",
    "\n",
    "            # mark missed tracks\n",
    "            for t_idx in unmatched_tracks:\n",
    "                tracked_objects[t_idx].mark_missed()\n",
    "\n",
    "            # create new tracks\n",
    "            # for d_idx in unmatched_dets:\n",
    "                # tracked_objects.append(TrackedObject(detections[d_idx]))\n",
    "            \n",
    "            for d_idx in unmatched_dets:\n",
    "                det = detections[d_idx]\n",
    "                # With condition to avoid duplicates\n",
    "                if not overlaps_existing_track(det, tracked_objects):\n",
    "                    tracked_objects.append(TrackedObject(det))\n",
    "\n",
    "            # remove dead tracks\n",
    "            tracked_objects = [\n",
    "                t for t in tracked_objects if t.missed <= MAX_MISSED\n",
    "            ]\n",
    "\n",
    "\n",
    "        # --- draw all detections ---\n",
    "        for det in detections:\n",
    "            x1, y1, x2, y2 = map(int, det.bbox)\n",
    "            # BRG\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # --- draw unmatched detections (orange) ---\n",
    "        for d_idx in unmatched_dets:\n",
    "            det = detections[d_idx]\n",
    "            x1, y1, x2, y2 = map(int, det.bbox)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Tracker-only update\n",
    "        for track in tracked_objects:\n",
    "            track.update_from_tracker(frame)\n",
    "\n",
    "        # No detections: mark all as missed\n",
    "        for track in tracked_objects:\n",
    "            track.mark_missed()\n",
    "\n",
    "        # remove dead tracks\n",
    "        tracked_objects = [\n",
    "            t for t in tracked_objects if t.missed <= MAX_MISSED\n",
    "        ]\n",
    "\n",
    "\n",
    "    if frame_idx%30 == 0:\n",
    "        # Create a sorted list of IOU values between all tracked objects\n",
    "        iou_values = []\n",
    "        for i in range(len(tracked_objects)):\n",
    "            for j in range(i + 1, len(tracked_objects)):\n",
    "                iou_score = iou(tracked_objects[i].bbox, tracked_objects[j].bbox)\n",
    "                iou_values.append((tracked_objects[i].id, tracked_objects[j].id, iou_score))\n",
    "        iou_values.sort(key=lambda x: x[2], reverse=True)\n",
    "        print(f'Frame {frame_idx}: Top IOU values between tracked objects:')\n",
    "        for id1, id2, score in iou_values[:5]:  # Print top 5 IOU values\n",
    "            print(f'  IDs {id1} & {id2}: IOU = {score:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "    # On top right corner, print frame idx, number of active tracks and info if it's yolo frame or not:\n",
    "    info_text = f'Frame {frame_idx}; Duration {frame_idx/fps:.2f}s; Active Tracks: {len(tracked_objects)}; ' + \\\n",
    "                ('[YOLO]' if use_yolo else '[Trac]')\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        info_text,\n",
    "        (10, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (0, 255, 255),\n",
    "        2,\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    if frame_idx % 10 == 0:\n",
    "        print(f'Frame {frame_idx}; Duration {frame_idx/fps:.2f}: {len(tracked_objects)} active tracks')\n",
    "        # Print number of matches, unmatched tracks, unmatched detections\n",
    "        print(f'  Matches: {len(matches)}, Unmatched Tracks: {len(unmatched_tracks)}, Unmatched Detections: {len(unmatched_dets)}')\n",
    "\n",
    "\n",
    "    # --- draw ---\n",
    "    for obj in tracked_objects:\n",
    "        x1, y1, x2, y2 = map(int, obj.bbox)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"ID {obj.id}\",\n",
    "            (x1, y1 - 5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "    \n",
    "    # Update timeticks for all tracked objects\n",
    "    for obj_id, obj in enumerate(tracked_objects):\n",
    "        obj.update_timeticks(frame_idx, fps)\n",
    "\n",
    "        obj_speed = estimate_speed(obj)\n",
    "        if frame_idx % 10 == 0:\n",
    "            if obj_speed is not None:\n",
    "                print(f'{obj.id} : {obj_speed:.2f} [m/s] : {(obj_speed*3.6):.2f} [km/h]')\n",
    "\n",
    "    \n",
    "\n",
    "    if frame_idx % 4 == 0:\n",
    "        gif_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    gif_writer.append_data(gif_frame)\n",
    "\n",
    "    # Add early stop for testing\n",
    "    # if frame_idx >= 180:\n",
    "    if frame_idx >= 30:\n",
    "        break\n",
    "\n",
    "    writer.write(frame)\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "gif_writer.close()\n",
    "\n",
    "print(f\"Writer opened: {writer.isOpened()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86450903",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(\"Outputs/tracked_output.gif\", embed=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efa505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Video(\"Inputs/video.mp4\", embed=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.legacy.TrackerKCF_create()\n",
    "# cv2.TrackerKCF.create()\n",
    "# cv2.TrackerCSRT_create()\n",
    "# cv2.TrackerCSRT_create()\n",
    "cv2.Tracker_create()\n",
    "# cv2.TrackerKCF_create()\n",
    "print(cv2.__version__)\n",
    "print(cv2.getBuildInformation())\n",
    "\n",
    "\n",
    "\n",
    "# The issue is from opencv-python, uninstall it and install cv2 using opencv-contrib-python. That solved it!\n",
    "\n",
    "\n",
    "# tracker_type = 'KCF'\n",
    "# # Initialize tracker\n",
    "# if tracker_type == \"BOOSTING\":\n",
    "#     tracker = cv2.legacy.TrackerBoosting.create()\n",
    "# elif tracker_type == \"MIL\":\n",
    "#     tracker = cv2.legacy.TrackerMIL.create()\n",
    "# elif tracker_type == \"KCF\":\n",
    "#     tracker = cv2.TrackerKCF.create()\n",
    "# elif tracker_type == \"CSRT\":\n",
    "#     tracker = cv2.legacy.TrackerCSRT.create()\n",
    "# elif tracker_type == \"TLD\":\n",
    "#     tracker = cv2.legacy.TrackerTLD.create()\n",
    "# elif tracker_type == \"MEDIANFLOW\":\n",
    "#     tracker = cv2.legacy.TrackerMedianFlow.create()\n",
    "# elif tracker_type == \"GOTURN\":\n",
    "#     tracker = cv2.TrackerGOTURN.create()\n",
    "# else:\n",
    "#     tracker = cv2.legacy.TrackerMOSSE.create()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
